{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12f6324",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-21T17:35:56.263819Z",
     "iopub.status.busy": "2022-07-21T17:35:56.263420Z",
     "iopub.status.idle": "2022-07-21T17:36:06.967170Z",
     "shell.execute_reply": "2022-07-21T17:36:06.966312Z"
    },
    "papermill": {
     "duration": 10.715216,
     "end_time": "2022-07-21T17:36:06.970521",
     "exception": false,
     "start_time": "2022-07-21T17:35:56.255305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nlp-getting-started/sample_submission.csv\n",
      "/kaggle/input/nlp-getting-started/train.csv\n",
      "/kaggle/input/nlp-getting-started/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, Dropout, TextVectorization\n",
    "    \n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c18c89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T17:36:06.982989Z",
     "iopub.status.busy": "2022-07-21T17:36:06.982177Z",
     "iopub.status.idle": "2022-07-21T17:36:07.154425Z",
     "shell.execute_reply": "2022-07-21T17:36:07.153432Z"
    },
    "papermill": {
     "duration": 0.180521,
     "end_time": "2022-07-21T17:36:07.156573",
     "exception": false,
     "start_time": "2022-07-21T17:36:06.976052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three people died from the heat wave so far</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Haha South Tampa is getting flooded hah- WAIT ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#raining #flooding #Florida #TampaBay #Tampa 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Flood in Bago Myanmar #We arrived Bago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Damage to school bus on 80 in multi car crash ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What's up man?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I love fruits</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer is lovely</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My car is so fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a goooooooaaaaaal!!!!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword location                                               text  target\n",
       "id                                                                            \n",
       "1      NaN      NaN  Our Deeds are the Reason of this #earthquake M...       1\n",
       "4      NaN      NaN             Forest fire near La Ronge Sask. Canada       1\n",
       "5      NaN      NaN  All residents asked to 'shelter in place' are ...       1\n",
       "6      NaN      NaN  13,000 people receive #wildfires evacuation or...       1\n",
       "7      NaN      NaN  Just got sent this photo from Ruby #Alaska as ...       1\n",
       "8      NaN      NaN  #RockyFire Update => California Hwy. 20 closed...       1\n",
       "10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...       1\n",
       "13     NaN      NaN  I'm on top of the hill and I can see a fire in...       1\n",
       "14     NaN      NaN  There's an emergency evacuation happening now ...       1\n",
       "15     NaN      NaN  I'm afraid that the tornado is coming to our a...       1\n",
       "16     NaN      NaN        Three people died from the heat wave so far       1\n",
       "17     NaN      NaN  Haha South Tampa is getting flooded hah- WAIT ...       1\n",
       "18     NaN      NaN  #raining #flooding #Florida #TampaBay #Tampa 1...       1\n",
       "19     NaN      NaN            #Flood in Bago Myanmar #We arrived Bago       1\n",
       "20     NaN      NaN  Damage to school bus on 80 in multi car crash ...       1\n",
       "23     NaN      NaN                                     What's up man?       0\n",
       "24     NaN      NaN                                      I love fruits       0\n",
       "25     NaN      NaN                                   Summer is lovely       0\n",
       "26     NaN      NaN                                  My car is so fast       0\n",
       "28     NaN      NaN                       What a goooooooaaaaaal!!!!!!       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv',index_col = 0, on_bad_lines = \"skip\")\n",
    "test_data = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv',index_col = 0, on_bad_lines = \"skip\")\n",
    "train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9bf2096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T17:36:07.169301Z",
     "iopub.status.busy": "2022-07-21T17:36:07.168974Z",
     "iopub.status.idle": "2022-07-21T17:36:07.178939Z",
     "shell.execute_reply": "2022-07-21T17:36:07.177938Z"
    },
    "papermill": {
     "duration": 0.018888,
     "end_time": "2022-07-21T17:36:07.181155",
     "exception": false,
     "start_time": "2022-07-21T17:36:07.162267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text    Forest fire near La Ronge Sask. Canada\n",
      "Name: 4, dtype: object\n",
      "(7613, 1)\n",
      "(7613,)\n",
      "(3263, 0)\n"
     ]
    }
   ],
   "source": [
    "train_x = train_data.iloc[:,:-1]\n",
    "train_y = train_data.iloc[:, -1]\n",
    "train_x = train_x.drop(columns=['keyword', 'location'])\n",
    "\n",
    "test_x = test_data.iloc[:,:-1]\n",
    "test_x = test_x.drop(columns=['keyword', 'location'])\n",
    "\n",
    "print(train_x.iloc[1])\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df53da4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T17:36:07.193829Z",
     "iopub.status.busy": "2022-07-21T17:36:07.193501Z",
     "iopub.status.idle": "2022-07-21T17:36:07.199027Z",
     "shell.execute_reply": "2022-07-21T17:36:07.197819Z"
    },
    "papermill": {
     "duration": 0.014612,
     "end_time": "2022-07-21T17:36:07.201198",
     "exception": false,
     "start_time": "2022-07-21T17:36:07.186586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a689ff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T17:36:07.213279Z",
     "iopub.status.busy": "2022-07-21T17:36:07.212978Z",
     "iopub.status.idle": "2022-07-21T17:36:07.219762Z",
     "shell.execute_reply": "2022-07-21T17:36:07.218831Z"
    },
    "papermill": {
     "duration": 0.015623,
     "end_time": "2022-07-21T17:36:07.222294",
     "exception": false,
     "start_time": "2022-07-21T17:36:07.206671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5100, 1)\n",
      "(5100,)\n",
      "(3263, 0)\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.33, random_state = 42)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edefacab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T17:36:07.235650Z",
     "iopub.status.busy": "2022-07-21T17:36:07.235258Z",
     "iopub.status.idle": "2022-07-21T17:36:07.248866Z",
     "shell.execute_reply": "2022-07-21T17:36:07.247833Z"
    },
    "papermill": {
     "duration": 0.023043,
     "end_time": "2022-07-21T17:36:07.251195",
     "exception": false,
     "start_time": "2022-07-21T17:36:07.228152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the size of the vocabulary we'll use\n",
    "vocab_size = 12000\n",
    "maxlen = 150\n",
    "\n",
    "def preprocess_twitter(train_x, val_x, test_x, num_words=vocab_size, maxlen=maxlen, vectorize=False):\n",
    "    \n",
    "    #np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "    #train, testval = imdb.load_data(num_words=num_words, maxlen=maxlen, oov_char=0)\n",
    "    #np.warnings.filterwarnings('default', category=np.VisibleDeprecationWarning)   \n",
    "\n",
    "    ### Process the data\n",
    "    ### Merge train and testval, but then split again into train, test, val sets (according to prop_vec). You can use utils.train_test_val_split().)\n",
    "    ### - If vectorize=True, then you must encode the features of each example into vectors of vocab_size entries\n",
    "    ### such that entry i contains the number of time word i appeared in the sequence\n",
    "    ### - If vectorize=False, then you must encode the features of each examples as a sequence of size maxlen (represented as a np.array()).\n",
    "    ### Make sure to pad sequences with 0 as appropriate.\n",
    "    ###* put your code here (~10-15 lines) *###\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    \n",
    "    #train_x, train_y = trainval\n",
    "    #test_x, test_y = test\n",
    "    \n",
    "    #all_x = np.concatenate([train_x, test_x])\n",
    "    #all_y = np.concatenate([train_y, test_y])\n",
    "    \n",
    "    \n",
    "    if vectorize:\n",
    "        tokenizer = keras.preprocessing.text.Tokenizer(num_words = vocab_size, lower=False, char_level=True)\n",
    "        train_x = tokenizer.sequences_to_matrix(train_x, mode = 'count')\n",
    "        val_x = tokenizer.sequences_to_matrix(val_x, mode = 'count')\n",
    "        test_x = tokenizer.sequences_to_matrix(test_x, mode = 'count')\n",
    "                                                       \n",
    "    else:\n",
    "        all_x = pad_sequences(all_x, maxlen=maxlen)\n",
    "\n",
    "    #train_x, train_y, test_x, test_y, val_x, val_y = utils.train_test_val_split(all_x, all_y, prop_vec)\n",
    "\n",
    "    return train_x, test_x, val_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c2aace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T17:36:07.264203Z",
     "iopub.status.busy": "2022-07-21T17:36:07.263897Z",
     "iopub.status.idle": "2022-07-21T17:36:07.274273Z",
     "shell.execute_reply": "2022-07-21T17:36:07.273034Z"
    },
    "papermill": {
     "duration": 0.020001,
     "end_time": "2022-07-21T17:36:07.276856",
     "exception": false,
     "start_time": "2022-07-21T17:36:07.256855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_compile_rnn(input_shape=[None], embedding_size=128, num_outputs=1, verbose=False): \n",
    "    \n",
    "    from tensorflow.keras.layers import Embedding, GRU, LSTM\n",
    "    \n",
    "    text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\n",
    "    max_features = 4000  # Maximum vocab size.\n",
    "    max_len = 4  # Sequence length to pad the outputs to.\n",
    "\n",
    "    vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "                                            max_tokens=max_features,\n",
    "                                            output_mode='int',\n",
    "                                            output_sequence_length=max_len)\n",
    "    \n",
    "    vectorize_layer.adapt(text_dataset.batch(64))\n",
    "    \n",
    "    \n",
    "    model = keras.models.Sequential(name='twitter-RNN')\n",
    "        \n",
    "        \n",
    "    model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "    model.add(vectorize_layer)\n",
    "\n",
    "    \n",
    "    model.add(Embedding(input_dim = vocab_size, output_dim = embedding_size))\n",
    "    \n",
    "    model.add(GRU(64, return_sequences=True, name='gru1'))\n",
    "    model.add(GRU(32, return_sequences=True, name='gru2'))\n",
    "    model.add(GRU(24, return_sequences=True, name='gru3'))\n",
    "    model.add(GRU(8, name='gru4'))\n",
    "    \n",
    "    model.add(Dense(num_outputs, activation='sigmoid', name='output'))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "        \n",
    "    opt = keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83fe503e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T17:36:07.289490Z",
     "iopub.status.busy": "2022-07-21T17:36:07.289047Z",
     "iopub.status.idle": "2022-07-21T17:36:08.468233Z",
     "shell.execute_reply": "2022-07-21T17:36:08.466798Z"
    },
    "papermill": {
     "duration": 1.188537,
     "end_time": "2022-07-21T17:36:08.470809",
     "exception": false,
     "start_time": "2022-07-21T17:36:07.282272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 17:36:07.304342: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-07-21 17:36:07.516493: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"twitter-RNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 4, 128)            1536000   \n",
      "_________________________________________________________________\n",
      "gru1 (GRU)                   (None, 4, 64)             37248     \n",
      "_________________________________________________________________\n",
      "gru2 (GRU)                   (None, 4, 32)             9408      \n",
      "_________________________________________________________________\n",
      "gru3 (GRU)                   (None, 4, 24)             4176      \n",
      "_________________________________________________________________\n",
      "gru4 (GRU)                   (None, 8)                 816       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,587,657\n",
      "Trainable params: 1,587,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "model = create_compile_rnn(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3e8af01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T17:36:08.484944Z",
     "iopub.status.busy": "2022-07-21T17:36:08.484590Z",
     "iopub.status.idle": "2022-07-21T17:36:22.438763Z",
     "shell.execute_reply": "2022-07-21T17:36:22.437948Z"
    },
    "papermill": {
     "duration": 13.964041,
     "end_time": "2022-07-21T17:36:22.441294",
     "exception": false,
     "start_time": "2022-07-21T17:36:08.477253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "40/40 [==============================] - 11s 79ms/step - loss: 0.6855 - accuracy: 0.5659 - val_loss: 0.6824 - val_accuracy: 0.5754\n",
      "Epoch 2/3\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6841 - accuracy: 0.5678 - val_loss: 0.6815 - val_accuracy: 0.5754\n",
      "Epoch 3/3\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6845 - accuracy: 0.5678 - val_loss: 0.6814 - val_accuracy: 0.5754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe550ed1910>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_epochs = 3\n",
    "batch_size = 128\n",
    "\n",
    "model.fit(train_x, train_y, epochs=max_epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3e987",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-19T00:20:26.964482Z",
     "iopub.status.busy": "2022-07-19T00:20:26.963742Z",
     "iopub.status.idle": "2022-07-19T00:20:26.970578Z",
     "shell.execute_reply": "2022-07-19T00:20:26.969017Z",
     "shell.execute_reply.started": "2022-07-19T00:20:26.964438Z"
    },
    "papermill": {
     "duration": 0.011228,
     "end_time": "2022-07-21T17:36:22.464603",
     "exception": false,
     "start_time": "2022-07-21T17:36:22.453375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a54fb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-19T00:20:46.953058Z",
     "iopub.status.busy": "2022-07-19T00:20:46.952681Z",
     "iopub.status.idle": "2022-07-19T00:20:47.378835Z",
     "shell.execute_reply": "2022-07-19T00:20:47.377572Z",
     "shell.execute_reply.started": "2022-07-19T00:20:46.953030Z"
    },
    "papermill": {
     "duration": 0.011527,
     "end_time": "2022-07-21T17:36:22.488093",
     "exception": false,
     "start_time": "2022-07-21T17:36:22.476566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c32854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-19T00:21:05.122473Z",
     "iopub.status.busy": "2022-07-19T00:21:05.121946Z",
     "iopub.status.idle": "2022-07-19T00:21:05.499833Z",
     "shell.execute_reply": "2022-07-19T00:21:05.498675Z",
     "shell.execute_reply.started": "2022-07-19T00:21:05.122411Z"
    },
    "papermill": {
     "duration": 0.011419,
     "end_time": "2022-07-21T17:36:22.511346",
     "exception": false,
     "start_time": "2022-07-21T17:36:22.499927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39.681684,
   "end_time": "2022-07-21T17:36:25.198982",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-21T17:35:45.517298",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
